{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import csv\n",
    "from transformers import MaskFormerImageProcessor, MaskFormerForInstanceSegmentation\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Scott's Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "Some weights of MaskFormerForInstanceSegmentation were not initialized from the model checkpoint at facebook/maskformer-swin-base-ade and are newly initialized because the shapes did not match:\n",
      "- class_predictor.weight: found shape torch.Size([151, 256]) in the checkpoint and torch.Size([5, 256]) in the model instantiated\n",
      "- class_predictor.bias: found shape torch.Size([151]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "- criterion.empty_weight: found shape torch.Size([151]) in the checkpoint and torch.Size([5]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for classes\n",
    "id2label = {\n",
    "    0: \"unlabeled\",\n",
    "    1: \"background\",\n",
    "    2: \"disc\",\n",
    "    3: \"cup\"\n",
    "}\n",
    "\n",
    "\n",
    "def color_palette():\n",
    "    \"\"\"Color palette that maps each class to RGB values.\n",
    "    \n",
    "    This one is actually taken from ADE20k.\n",
    "    \"\"\"\n",
    "    return [[255,0,0], [0,255,0], [0,0,255]]\n",
    "\n",
    "# for vis\n",
    "palette = color_palette()\n",
    "\n",
    "# transforms\n",
    "ADE_MEAN = np.array([0.709, 0.439, 0.287])\n",
    "ADE_STD = np.array([0.210, 0.220, 0.199])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(width=512, height=512),\n",
    "    A.Normalize(mean=ADE_MEAN, std=ADE_STD)\n",
    "])\n",
    "\n",
    "# BEGIN TEST\n",
    "\n",
    "device = 'cuda:0'\n",
    "# Replace the head of the pre-trained model\n",
    "model = MaskFormerForInstanceSegmentation.from_pretrained(\"facebook/maskformer-swin-base-ade\",\n",
    "                                                            id2label=id2label,\n",
    "                                                            ignore_mismatched_sizes=True).to(device)\n",
    "\n",
    "# Specify the path to the state dictionary\n",
    "model_savedir = '/sddata/projects/Conformal_Uncertainty_Quantification/models'\n",
    "model_filename = '/sddata/projects/glaucoma_segmentation_scott/best_maskformer_weights/best_model.pt'\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load(model_filename)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_single_channel(image_path):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert to RGB mode if not already in that mode\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    # Compute the max value along the channel axis\n",
    "    max_channel = np.argmax(img_array, axis=2) + 1  # Adding 1 to make red 1, green 2, blue 3\n",
    "\n",
    "    # Define the color mappings after max channel computation\n",
    "    color_map = {\n",
    "        1: 1,  # Red\n",
    "        2: 2,  # Green\n",
    "        3: 3,  # Blue\n",
    "    }\n",
    "\n",
    "    # Create masks based on the max channel values\n",
    "    masks = np.zeros((img_array.shape[0], img_array.shape[1], len(color_map)), dtype=np.uint8)\n",
    "    for index, label in color_map.items():\n",
    "        masks[:, :, index - 1] = max_channel == label\n",
    "\n",
    "    # Create the single-channel image using the masks\n",
    "    single_channel_image = np.argmax(masks, axis=2) + 1  # Adding 1 to adjust labels\n",
    "\n",
    "    return single_channel_image\n",
    "\n",
    "def convert_grayscale_disc_image(image_path):\n",
    "    # Open the image\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert to grayscale mode if not already in that mode\n",
    "    image = image.convert('L')\n",
    "\n",
    "    # Convert the image to a NumPy array\n",
    "    img_array = np.array(image, dtype=np.uint8)\n",
    "\n",
    "    # Replace black pixels with 1 (background) and white pixels with 2 (disc)\n",
    "    img_array[img_array >= 1] = 2  # Assuming white pixels have intensity 255\n",
    "    img_array[img_array == 0] = 1  # Assuming black pixels have intensity 0\n",
    "\n",
    "    return img_array\n",
    "\n",
    "\n",
    "class ImageSegmentationDataset(Dataset):\n",
    "    \"\"\"Image segmentation dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, images, masks, transform, data_root_dir, convert_disc=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "        self.transform = transform\n",
    "        self.data_root_dir = data_root_dir\n",
    "        self.convert_disc = convert_disc\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path_to_img = self.data_root_dir + 'images/' + self.images[idx]\n",
    "        path_to_mask = self.data_root_dir + 'labels/' + self.masks[idx]\n",
    "        if self.data_root_dir == '/projects/skinder@xsede.org/seg_paper/test_datasets/rimone/':\n",
    "            path_to_img = self.images[idx].split('/')[-1]\n",
    "            path_to_img = self.data_root_dir + path_to_img\n",
    "            path_to_mask = self.masks[idx].split('/')[-1]\n",
    "            path_to_mask = self.data_root_dir + path_to_mask\n",
    "             \n",
    "        original_image = np.array(Image.open(path_to_img))\n",
    "        original_segmentation_map = None\n",
    "        if self.convert_disc:\n",
    "            original_segmentation_map = convert_grayscale_disc_image(path_to_mask)\n",
    "        else:\n",
    "            original_segmentation_map = convert_to_single_channel(path_to_mask)\n",
    "        \n",
    "        transformed = self.transform(image=original_image, mask=original_segmentation_map)\n",
    "        image, segmentation_map = transformed['image'], transformed['mask']\n",
    "\n",
    "        # convert to C, H, W\n",
    "        image = image.transpose(2,0,1)\n",
    "\n",
    "        return image, segmentation_map, original_image, original_segmentation_map\n",
    "\n",
    "\n",
    "# # Load the CSV file\n",
    "# test_csv_file_path = '/scratch/alpine/skinder@xsede.org/glaucomachris/r1.csv'  # Replace with the actual path\n",
    "# data_df = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# # Note the ::5 if you use the test set\n",
    "# test_image_paths = data_df['Cropped_Images'].tolist()[::5]  # Replace with the actual column name\n",
    "# test_mask_paths = data_df['Cropped_Disks'].tolist()[::5]  # Replace with the actual column name\n",
    "\n",
    "test_dataset = ImageSegmentationDataset(test_image_paths, test_mask_paths, transform=test_transform, data_root_dir='/projects/skinder@xsede.org/seg_paper/test_datasets/rimone/', convert_disc=True)\n",
    "\n",
    "# Create a preprocessor\n",
    "preprocessor = MaskFormerImageProcessor(ignore_index=0, reduce_labels=False, do_resize=False, do_rescale=False, do_normalize=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
